{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "부록2-Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjbcccFwifgR"
      },
      "source": [
        "# 학습이 잘 되는 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSwkPOe7joJq"
      },
      "source": [
        "사용할 레이어\r\n",
        "- `tf.keras.layers.BatchNormalization()`\r\n",
        "- `tf.keras.layers.Activation('swish')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWxzo_OWksDW"
      },
      "source": [
        "## Boston"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32TMyLfQiTOq",
        "outputId": "62e7fd7b-5fa1-421f-bf95-d86b8f80e549"
      },
      "source": [
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "boston = pd.read_csv('boston.csv')\r\n",
        "indep = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\r\n",
        "       'ptratio', 'b', 'lstat']]\r\n",
        "dep = boston[['medv']]\r\n",
        "print(indep.shape, dep.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13) (506, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxeibhs1i1LK"
      },
      "source": [
        "X = tf.keras.layers.Input(shape=[13])\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(10)(X)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(10)(H)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(10)(H)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "Y = tf.keras.layers.Dense(1)(H)\r\n",
        "model = tf.keras.models.Model(X, Y)\r\n",
        "model.compile(loss='mse')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ky0yKq6jyTG",
        "outputId": "23619010-f23d-45cf-8a64-5deffc49de05"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 13)]              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 431\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_xfVZgGj0wX",
        "outputId": "fcded0bc-3fe0-4a9b-d6a0-068e8809b4f4"
      },
      "source": [
        "model.fit(indep,dep,epochs=1000, verbose=0)\r\n",
        "model.fit(indep,dep,epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.3409\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.3333\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.4857\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.2811\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.1542\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.8176\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.8834\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.7544\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.4008\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.7238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdad80b6208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIMxISd6j41l"
      },
      "source": [
        "print(model.predict(indep[:5]))\r\n",
        "print(dep[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB8BLUtvkwLV"
      },
      "source": [
        "## Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVM519BPk1vF",
        "outputId": "7a5b7889-d02a-444d-9f51-645e31adfd0b"
      },
      "source": [
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "iris = pd.read_csv('iris.csv')\r\n",
        "encoding = pd.get_dummies(iris)\r\n",
        "encoding.head()\r\n",
        "\r\n",
        "indep = encoding[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\r\n",
        "dep = encoding[[ '품종_setosa', '품종_versicolor',\r\n",
        "       '품종_virginica']]\r\n",
        "print(indep.shape, dep.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qufhIj31k6DQ"
      },
      "source": [
        "X = tf.keras.layers.Input(shape=[4])\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(5)(X)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(5)(H)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "H = tf.keras.layers.Dense(5)(X)\r\n",
        "H = tf.keras.layers.BatchNormalization()(H)\r\n",
        "H = tf.keras.layers.Activation('swish')(H)\r\n",
        "\r\n",
        "Y = tf.keras.layers.Dense(3, activation='softmax')(H)\r\n",
        "model = tf.keras.models.Model(X, Y)\r\n",
        "model.compile(loss='categorical_crossentropy',  metrics='accuracy')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l6CT-DBk6sd",
        "outputId": "ad036120-a4bd-4e01-aad2-d7b681b2a31d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 25        \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5)                 20        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 18        \n",
            "=================================================================\n",
            "Total params: 63\n",
            "Trainable params: 53\n",
            "Non-trainable params: 10\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Y6l77zk9vw",
        "outputId": "e09dca52-06e7-49a9-dc6f-81ca4e2e0b1c"
      },
      "source": [
        "model.fit(indep,dep,epochs=200)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.1296 - accuracy: 0.3757\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0870 - accuracy: 0.3570\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0828 - accuracy: 0.4207\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0805 - accuracy: 0.3843\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0234 - accuracy: 0.4578\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0245 - accuracy: 0.4990\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.5109\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.6004\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0155 - accuracy: 0.5677\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.6448\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.6934\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9813 - accuracy: 0.6769\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9494 - accuracy: 0.7113\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9290 - accuracy: 0.7125\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9340 - accuracy: 0.6976\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.7097\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9062 - accuracy: 0.7567\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8804 - accuracy: 0.7406\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8697 - accuracy: 0.7590\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8565 - accuracy: 0.7497\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8419 - accuracy: 0.7750\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8355 - accuracy: 0.7626\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8413 - accuracy: 0.7311\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8282 - accuracy: 0.7558\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.7781\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.7843\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.7620\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.7542\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7872 - accuracy: 0.7487\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.7987\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.8103\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7869\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.7735\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7386 - accuracy: 0.7870\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.7703\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.8294\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7987\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.7717\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.8151\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.7762\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.7865\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7847\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.7852\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.7936\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7521\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7904\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.7888\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.8180\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7726\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7999\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.8195\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7946\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.7662\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.7556\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.8168\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7957\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.8018\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7683\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8194\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.8039\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.8275\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7911\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8306\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.8092\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8528\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7816\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8004\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7863\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8176\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.8325\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8276\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7845\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8036\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8269\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8350\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8259\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7793\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.8312\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8224\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8528\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8032\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7942\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8002\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8778\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8143\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8599\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7886\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8193\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8508\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8525\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8228\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8646\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8347\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8581\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8173\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8270\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8716\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8264\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8467\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8465\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8591\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8873\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8387\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8293\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8459\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8578\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8334\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8537\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8378\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8190\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8206\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8359\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8949\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8505\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8739\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8721\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8752\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8301\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8695\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8832\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8387\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8457\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8318\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8882\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8719\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8405\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8671\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8949\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8858\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8661\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8357\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8538\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8609\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8858\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8692\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8107\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8774\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8723\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8835\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8828\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8574\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8775\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8462\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8702\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8327\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8417\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8570\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8322\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2967 - accuracy: 0.8837\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8741\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8840\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8456\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8985\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8704\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8714\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8440\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.9036\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8952\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8750\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8919\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.9163\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.9094\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.9146\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8554\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8804\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.9137\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8984\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8863\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9166\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9103\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.9128\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8785\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8957\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.9007\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.8710\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8898\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8667\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8781\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.9084\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8941\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8964\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.9040\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8682\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8629\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.9090\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8863\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.9133\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8972\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.9047\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8985\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9094\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9238\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8768\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8961\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8998\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9044\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8828\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9079\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.9036\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdad8033630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZhIN5yZlBPf",
        "outputId": "d324112e-8783-40de-ef96-cc376b81d0b7"
      },
      "source": [
        "print(model.predict(indep[:5]))\r\n",
        "print(dep[:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9926454e-01 6.3928135e-04 9.6097676e-05]\n",
            " [9.9387580e-01 5.6365589e-03 4.8771864e-04]\n",
            " [9.9749869e-01 2.2840234e-03 2.1727178e-04]\n",
            " [9.8828018e-01 1.1081832e-02 6.3799851e-04]\n",
            " [9.9941301e-01 5.1160890e-04 7.5396347e-05]]\n",
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n",
            "1          1              0             0\n",
            "2          1              0             0\n",
            "3          1              0             0\n",
            "4          1              0             0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}